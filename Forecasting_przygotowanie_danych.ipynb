{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Forecasting - przygotowanie danych",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNk+0Wqsiq/aJNKrk41rKrk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mbednarski/sda-rnn/blob/master/Forecasting_przygotowanie_danych.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importy\n",
        "Zaczymamy od zaimportowania potrzebnych bibliotek"
      ],
      "metadata": {
        "id": "0V479m_FZWWn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpnRZ1gTUQ7P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wczytanie danych\n",
        "Na początek pobobieramy i rozpakowujemy dane."
      ],
      "metadata": {
        "id": "gWF0BIPiSZYc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = tf.keras.utils.get_file(\n",
        "    origin='https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip',\n",
        "    fname='jena_climate_2009_2016.csv.zip',\n",
        "    extract=True)\n",
        "csv_path, _ = os.path.splitext(zip_path)\n"
      ],
      "metadata": {
        "id": "J-ZfT9XfUUHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pobrany przez nas plik zawiera pomiary różnych parametrów pogodowych. Spórzmy na kilka pierwszysch wpisów aby wyrobić sobie intuicję."
      ],
      "metadata": {
        "id": "22gymVGFSjZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(csv_path)\n",
        "df"
      ],
      "metadata": {
        "id": "vy7Fk3hqStsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Widzimy, że dane zawierają wiele parmetrów. Naszym celem będzie predykcja temperatury (T (degC)). W tym celu będziemy używać nie tylko temperatury historycznej, ale także innych zmierzonych wartości.\n",
        "\n",
        "Dane były zbieranie z okresem 10 minut. Możemy powiedzieć że częstotliwość próbkowanania wynosi 5 razy na godzinę. W tym przypadku jest to ważne, gdyż temperatura ma charakter ciągły i pomiar odbywa się co pewien czas. W przypadku danych dyskretnych (np. sekwencja DNA, tekst) - nie mamy do czynienia z czasem pobrania próbki - po prostu mamy kolejne, następujące po sobie wartości.\n",
        "\n",
        "Na nasze potrzeby będziemy potrzebowali danych próbkowanych co godzinę. Dlatego najpierw wybierzmy odpowiednie wiersze:\n"
      ],
      "metadata": {
        "id": "ceAJzXdZS3sy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[5::6].copy()\n",
        "df"
      ],
      "metadata": {
        "id": "rozcN442S3R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EDA i preprocessing\n",
        "Przyjrzyjmy sie rozkładowi danych:"
      ],
      "metadata": {
        "id": "NpbYF4TwUDW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "IEOt-AFGU6r7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pytanie 1 (łatwe)\n",
        "Czy widzisz jakiś problem?\n",
        "\n",
        "### Pytanie 2 (średnie)\n",
        "Czy wiesz dlaczego wiatr jest podany w dwóch kolumnach? (wd (deg) oraz wv (m/s)). Pytanie może być bardzo trudnie jeżeli nigdy nie miałeś_aś styczności z takimi danymi.\n",
        "\n",
        "###Pytanie 3 (trudne)\n",
        "W jaki inny sposób możemy opisać dane nt. siły i kierunku wiatru? Jaki jest problem z obecną reprezentacją?"
      ],
      "metadata": {
        "id": "ljmWaNvcUPs2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Poprawianie outlierów. \n",
        "\n",
        "Wartość -9999 jest najprawdopodbniej błędna. Zamieńmy ją na zero.\n",
        "\n",
        "### Pytanie 4 (średnie)\n",
        "Dlaczego nie chcemy po prostu usunąć tych rekordów?"
      ],
      "metadata": {
        "id": "m97ggMWiVFKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bad_wind = df['wv (m/s)'] < 0 \n",
        "bad_max_wind =  df['max. wv (m/s)'] < 0\n",
        "print('Ilość rekordów z wadliwym wiatrem', bad_wind.sum())\n",
        "print('Ilość rekordów z wadliwym porywem wiatru', bad_max_wind.sum())\n",
        "df.loc[bad_wind, 'wv (m/s)'] = 0\n",
        "df.loc[bad_max_wind, 'max. wv (m/s)'] = 0\n"
      ],
      "metadata": {
        "id": "yBP5ozOPVeKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wiemy już, że azymut nie jest dobrą cechą. Najprościej będzie się jej pozbyć. Przy okazji usuńmy kolumnę ze stemplem czasowym. Nie będziemy go używać w modelu."
      ],
      "metadata": {
        "id": "xYfZGTmEWXKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns=['wd (deg)', 'Date Time'])\n",
        "df"
      ],
      "metadata": {
        "id": "GcEf0G2iVJfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zadanie 1 (trudne)\n",
        "Zaimplementuj kod który z kolumn wv (m/s) i wd (deg) utworzy dwie nowe - wind_x i wind_y. Nowe kolumny będą przechowywały wektor opisujący siłę i kierunek wiatru. Potrzebna będzie trygonometria ;)"
      ],
      "metadata": {
        "id": "aZ1H1t8uXIzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fearture engineering"
      ],
      "metadata": {
        "id": "7mkCBnS9Z3Cx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytanie 5 (trudne)\n",
        "Pogoda zmienia się sezonowo (w zimie i w nocy jest raczej zimniej niż latem i w dzień). W jaki sposób możemy wykonać feature engineering który doda odpowiednie kolumny?\n",
        "\n",
        "### Zadanie 2 (trudne)\n",
        "Zaimplementuj odpowiedź na pytanie 5 ;)\n",
        "\n",
        "### Zadanie 3 (bardzo trudne)\n",
        "Założyliśmy w ciemno, że temperatra zmienia się w cyklu dziennym i rocznym. Sprawdź czym jest szybka transformata fouriera i wykorzystaj ją do potwierdzenia/obalenia naszej intuicji. UWAGA: zadanie wymaga dużej pracy własnej i przyswojenia konkretnej dawki wiedzy."
      ],
      "metadata": {
        "id": "KCaFFx3bYoMJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Podział na zbiory treningowy/walidacyjny i testowy\n",
        "\n",
        "Podzielmy dane na zbiory train/val/test. Zwykle podziału dokonujemy losowo, tym razem jest inaczej. Pierwsze 70% trafi do zbiory treningowego, kolejne 15% do walidacyjnego a ostatne 15% do testowego. Zapewni to bardziej wiarygodną ewaluację - model testujemy na danych późniejszych niż treningowe. Dodatkowo w ten sposób będziemy mieli zapewnioną spójność wygenerowanych okien - o co chodzi dowiesz się wkrótce ;)"
      ],
      "metadata": {
        "id": "e4U_IezzavCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dset_len = len(df)\n",
        "df_train = df.iloc[0:int(dset_len*0.7)]\n",
        "df_val = df.iloc[int(dset_len*0.7):int(dset_len*0.85)]\n",
        "df_test = df.iloc[int(dset_len*0.85):]\n",
        "\n",
        "num_features = df.shape[1]\n",
        "len(df_train), len(df_val), len(df_test)"
      ],
      "metadata": {
        "id": "qFp4hT-hV5nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizacja/standaryzacja\n",
        "\n",
        "Sieć neuronowa potrzebuje danych numerycznych w standardowej postaci. Tzn, średnia każdej cechy powinna wynosić zero a jej odchylenie standardowe jeden. Dobra wiadomość jest taka, że dowolne dane możemy przekształcić do takiej formy przy użyciu wzoru:\n",
        "$$ z= \\frac{x-μ}{σ}$$\n",
        "\n",
        "UWAGA, średnią i odchylenie obliczamy ze zbioru treningowego! To bardzo ważne, inaczej mamy wyciek ze zbiorów val/test.\n",
        "\n",
        "### Pytanie 6 (trudne)\n",
        "Dlaczego jest to ważne?"
      ],
      "metadata": {
        "id": "1Bp7Kq81bsjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_mean = df_train.mean()\n",
        "train_std = df_train.std()\n",
        "\n",
        "df_train = (df_train - train_mean) / train_std\n",
        "df_val = (df_val - train_mean) / train_std\n",
        "df_test = (df_test - train_mean) / train_std"
      ],
      "metadata": {
        "id": "VuLw71EwhcUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.describe().round(3)"
      ],
      "metadata": {
        "id": "fJHPFN3Zh3ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Przyjrzyjmy sie jak rozład wygląda teraz:\n",
        "\n",
        "(W razie potrzemy omówimy funkcję `melt`)"
      ],
      "metadata": {
        "id": "xXTUB67we4r6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.violinplot(x='variable', y='value', data=df_train.melt())\n",
        "ax.grid()\n",
        "_ = ax.set_xticklabels(df_train.keys(), rotation=90)"
      ],
      "metadata": {
        "id": "WqO1kmgvh5sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To samo dla zbioru walidacyjnego"
      ],
      "metadata": {
        "id": "dydttSgOe8oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ax = sns.violinplot(x='variable', y='value', data=df_val.melt())\n",
        "ax.grid()\n",
        "_ = ax.set_xticklabels(df_val.keys(), rotation=90)"
      ],
      "metadata": {
        "id": "BpsJwEMkfCX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zapisanie zbiorów\n",
        "\n",
        "Mamy gotowe dane, teraz wystarczy je zapisać."
      ],
      "metadata": {
        "id": "mETQTs8JfTzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.to_csv('temp_train.csv')\n",
        "df_val.to_csv('temp_val.csv')\n",
        "df_test.to_csv('temp_test.csv')\n"
      ],
      "metadata": {
        "id": "26LvF8Lzfg_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Przygotowamie danych do użycia w modelu\n",
        "\n",
        "Nadal nie wiemy jak zakodować dane tak aby użyć ich w modelu. To za chwilę się zmiemi ;) "
      ],
      "metadata": {
        "id": "p1k6BVqlfwkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WindowGenerator():\n",
        "  def __init__(self, input_width, label_width, shift,\n",
        "               train_df=df_train, val_df=df_val, test_df=df_test,\n",
        "               label_columns=None):\n",
        "    # Store the raw data.\n",
        "    self.train_df = train_df\n",
        "    self.val_df = val_df\n",
        "    self.test_df = test_df\n",
        "\n",
        "    # Work out the label column indices.\n",
        "    self.label_columns = label_columns\n",
        "    if label_columns is not None:\n",
        "      self.label_columns_indices = {name: i for i, name in\n",
        "                                    enumerate(label_columns)}\n",
        "    self.column_indices = {name: i for i, name in\n",
        "                           enumerate(train_df.columns)}\n",
        "\n",
        "    # Work out the window parameters.\n",
        "    self.input_width = input_width\n",
        "    self.label_width = label_width\n",
        "    self.shift = shift\n",
        "\n",
        "    self.total_window_size = input_width + shift\n",
        "\n",
        "    self.input_slice = slice(0, input_width)\n",
        "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
        "\n",
        "    self.label_start = self.total_window_size - self.label_width\n",
        "    self.labels_slice = slice(self.label_start, None)\n",
        "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
        "\n",
        "  def __repr__(self):\n",
        "    return '\\n'.join([\n",
        "        f'Total window size: {self.total_window_size}',\n",
        "        f'Input indices: {self.input_indices}',\n",
        "        f'Label indices: {self.label_indices}',\n",
        "        f'Label column name(s): {self.label_columns}'])"
      ],
      "metadata": {
        "id": "TeC5AF-6s_In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_window(self, features):\n",
        "  inputs = features[:, self.input_slice, :]\n",
        "  labels = features[:, self.labels_slice, :]\n",
        "  if self.label_columns is not None:\n",
        "    labels = tf.stack(\n",
        "        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
        "        axis=-1)\n",
        "\n",
        "  # Slicing doesn't preserve static shape information, so set the shapes\n",
        "  # manually. This way the `tf.data.Datasets` are easier to inspect.\n",
        "  inputs.set_shape([None, self.input_width, None])\n",
        "  labels.set_shape([None, self.label_width, None])\n",
        "\n",
        "  return inputs, labels\n",
        "\n",
        "WindowGenerator.split_window = split_window"
      ],
      "metadata": {
        "id": "XqBGh46kiiPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(self, model=None, plot_col='T (degC)', max_subplots=3):\n",
        "  inputs, labels = self.example\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plot_col_index = self.column_indices[plot_col]\n",
        "  max_n = min(max_subplots, len(inputs))\n",
        "  for n in range(max_n):\n",
        "    plt.subplot(max_n, 1, n+1)\n",
        "    plt.ylabel(f'{plot_col} [normed]')\n",
        "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
        "             label='Inputs', marker='.', zorder=-10)\n",
        "\n",
        "    if self.label_columns:\n",
        "      label_col_index = self.label_columns_indices.get(plot_col, None)\n",
        "    else:\n",
        "      label_col_index = plot_col_index\n",
        "\n",
        "    if label_col_index is None:\n",
        "      continue\n",
        "\n",
        "\n",
        "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
        "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
        "    if model is not None:\n",
        "      predictions = model(inputs)\n",
        "      if len(predictions.shape) == 2:\n",
        "        predictions = tf.expand_dims(predictions,1)\n",
        "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
        "                  marker='X', edgecolors='k', label='Predictions',\n",
        "                  c='#ff7f0e', s=64)\n",
        "\n",
        "    if n == 0:\n",
        "      plt.legend()\n",
        "\n",
        "  plt.xlabel('Time [h]')\n",
        "\n",
        "WindowGenerator.plot = plot"
      ],
      "metadata": {
        "id": "r3j28RX4o9Vw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(self, data):\n",
        "  data = np.array(data, dtype=np.float32)\n",
        "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
        "      data=data,\n",
        "      targets=None,\n",
        "      sequence_length=self.total_window_size,\n",
        "      sequence_stride=1,\n",
        "      shuffle=True,\n",
        "      batch_size=32,)\n",
        "\n",
        "  ds = ds.map(self.split_window)\n",
        "\n",
        "  return ds\n",
        "\n",
        "WindowGenerator.make_dataset = make_dataset"
      ],
      "metadata": {
        "id": "UIMO2WmFp235"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@property\n",
        "def train(self):\n",
        "  return self.make_dataset(self.train_df)\n",
        "\n",
        "@property\n",
        "def val(self):\n",
        "  return self.make_dataset(self.val_df)\n",
        "\n",
        "@property\n",
        "def test(self):\n",
        "  return self.make_dataset(self.test_df)\n",
        "\n",
        "@property\n",
        "def example(self):\n",
        "  \"\"\"Get and cache an example batch of `inputs, labels` for plotting.\"\"\"\n",
        "  result = getattr(self, '_example', None)\n",
        "  if result is None:\n",
        "    # No example batch was found, so get one from the `.train` dataset\n",
        "    result = next(iter(self.train))\n",
        "    # And cache it for next time\n",
        "    self._example = result\n",
        "  return result\n",
        "\n",
        "WindowGenerator.train = train\n",
        "WindowGenerator.val = val\n",
        "WindowGenerator.test = test\n",
        "WindowGenerator.example = example"
      ],
      "metadata": {
        "id": "5TSkGyHn1gVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next_in_12_h = WindowGenerator(input_width=12, label_width=1, shift=1, label_columns=['T (degC)'])\n",
        "print(next_in_12_h)\n",
        "next_in_12_h.plot()"
      ],
      "metadata": {
        "id": "oWrs0jLF1m__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookahead_24h = WindowGenerator(input_width=24, label_width=1, shift=24, label_columns=['T (degC)'])\n",
        "print(lookahead_24h)\n",
        "lookahead_24h.plot()"
      ],
      "metadata": {
        "id": "-ry9fk4M1uWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continous_24h = WindowGenerator(input_width=48, label_width=24, shift=24, label_columns=['T (degC)'])\n",
        "print(continous_24h)\n",
        "continous_24h.plot()"
      ],
      "metadata": {
        "id": "emn_vTX818wY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JFcd4L4p2IVu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nK8Pnp8x3HqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pytanie 7 (średnie/trudne)\n",
        "\n",
        "Jaki baseline możemy wymyślić?"
      ],
      "metadata": {
        "id": "vnrILzLn35fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pytanie 8 (trudne)\n",
        "\n",
        "Czy istnieje górna granica skuteczności modelu której nie możemy przekroczyć?"
      ],
      "metadata": {
        "id": "_1mVNnDd4YS5"
      }
    }
  ]
}